{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract dataset 1\n",
    "!mkdir -p folder1 && curl -L \"https://public.roboflow.com/ds/7DC1HUigkh?key=bZnQAQXFuo\" -o folder1/roboflow.zip && unzip -d folder1 folder1/roboflow.zip && rm folder1/roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract dataset 2\n",
    "!mkdir -p folder2 && curl -L \"https://public.roboflow.com/ds/kJSM3h2MeM?key=FI4wHl2s8c\" -o folder2/roboflow.zip && unzip -d folder2 folder2/roboflow.zip && rm folder2/roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data loader\n",
    "!python data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the data\n",
    "!yolo val model=yolov8n.pt data=/content/folder4/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv8n on COCO8 for 3 epochs\n",
    "!yolo train model=yolov8n.pt data=/content/folder4/data.yaml epochs=3 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the trained model to TorchScript format\n",
    "!yolo export model=yolov8n.pt format=torchscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform prediction using the trained model on a sample image\n",
    "!yolo predict model=yolov8n.torchscript source='input.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                  Class     Images  Instances      Box(P          R      mAP50  mAP50-95)\n",
    "#                    all       4603      28993      0.742      0.387      0.449      0.235\n",
    "#                  biker       4603        536      0.509      0.425      0.414        0.2\n",
    "#                    car       4603      18953      0.836      0.739       0.81      0.497\n",
    "#             pedestrian       4603       3046      0.672      0.366      0.458      0.193\n",
    "#           trafficLight       4603        734      0.582      0.391      0.487      0.258\n",
    "#     trafficLight-Green       4603       1726      0.619       0.47      0.491      0.194\n",
    "# trafficLight-GreenLeft       4603         80          1          0      0.272      0.173\n",
    "#       trafficLight-Red       4603       1907      0.753      0.633      0.697      0.324\n",
    "#   trafficLight-RedLeft       4603        497      0.866      0.479      0.628      0.318\n",
    "#    trafficLight-Yellow       4603         73          1          0     0.0526     0.0283\n",
    "# trafficLight-YellowLeft       4603          8          1          0          0          0\n",
    "#                  truck       4603       1103      0.725      0.647      0.693      0.435\n",
    "#                pothole       4603        330      0.338      0.497      0.389      0.195"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
